{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chocolate_xception.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertocaiwu/ComputerVision/blob/master/coding/Chocolate_xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RuN0wfz9r69O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7246
        },
        "outputId": "08a846a8-fdfb-427a-e854-7c86728e9773"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.applications import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import backend as k\n",
        "\n",
        "# fix seed for reproducible results (only works on CPU, not GPU)\n",
        "seed = 9\n",
        "np.random.seed(seed=seed)\n",
        "tf.set_random_seed(seed=seed)\n",
        "\n",
        "# hyper parameters for model\n",
        "nb_classes = 32  # number of classes\n",
        "based_model_last_block_layer_number = 126  # value is based on based model selected.\n",
        "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
        "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
        "nb_epoch = 50  # number of iteration the algorithm gets trained.\n",
        "learn_rate = 1e-4  # sgd learning rate\n",
        "momentum = .9  # sgd momentum to avoid local minimum\n",
        "transformation_ratio = .05  # how aggressive will be the data augmentation/transformation\n",
        "\n",
        "\n",
        "def train(train_data_dir, validation_data_dir, model_path):\n",
        "    # Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
        "    base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "    # Top Model Block\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    # add your top layer block to your base model\n",
        "    model = Model(base_model.input, predictions)\n",
        "    print(model.summary())\n",
        "\n",
        "    # # let's visualize layer names and layer indices to see how many layers/blocks to re-train\n",
        "    # # uncomment when choosing based_model_last_block_layer\n",
        "    # for i, layer in enumerate(model.layers):\n",
        "    #     print(i, layer.name)\n",
        "\n",
        "    # first: train only the top layers (which were randomly initialized)\n",
        "    # i.e. freeze all layers of the based model that is already pre-trained.\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
        "    # To save augmentations un-comment save lines and add to your flow parameters.\n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                       rotation_range=transformation_ratio,\n",
        "                                       shear_range=transformation_ratio,\n",
        "                                       zoom_range=transformation_ratio,\n",
        "                                       cval=transformation_ratio,\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True)\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    os.makedirs(os.path.join(os.path.abspath(train_data_dir), '../preview'), exist_ok=True)\n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                        target_size=(img_width, img_height),\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical')\n",
        "    # save_to_dir=os.path.join(os.path.abspath(train_data_dir), '../preview')\n",
        "    # save_prefix='aug',\n",
        "    # save_format='jpeg')\n",
        "    # use the above 3 commented lines if you want to save and look at how the data augmentations look like\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                                  target_size=(img_width, img_height),\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical')\n",
        "\n",
        "    model.compile(optimizer='nadam',\n",
        "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
        "\n",
        "    top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
        "    callbacks_list = [\n",
        "        ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
        "        EarlyStopping(monitor='val_acc', patience=5, verbose=0)\n",
        "    ]\n",
        "\n",
        "    # Train Simple CNN\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=897// batch_size,\n",
        "                        epochs=nb_epoch / 5,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=64// batch_size,\n",
        "                        callbacks=callbacks_list)\n",
        "\n",
        "    # verbose\n",
        "    print(\"\\nStarting to Fine Tune Model\\n\")\n",
        "\n",
        "    # add the best weights from the train top model\n",
        "    # at this point we have the pre-train weights of the base model and the trained weight of the new/added top model\n",
        "    # we re-load model weights to ensure the best epoch is selected and not the last one.\n",
        "    model.load_weights(top_weights_path)\n",
        "\n",
        "    # based_model_last_block_layer_number points to the layer in your model you want to train.\n",
        "    # For example if you want to train the last block of a 19 layer VGG16 model this should be 15\n",
        "    # If you want to train the last Two blocks of an Inception model it should be 172\n",
        "    # layers before this number will used the pre-trained weights, layers above and including this number\n",
        "    # will be re-trained based on the new data.\n",
        "    for layer in model.layers[:based_model_last_block_layer_number]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[based_model_last_block_layer_number:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # compile the model with a SGD/momentum optimizer\n",
        "    # and a very slow learning rate.\n",
        "    model.compile(optimizer='nadam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
        "    final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n",
        "    callbacks_list = [\n",
        "        ModelCheckpoint(final_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
        "        EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
        "    ]\n",
        "\n",
        "    # fine-tune the model\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=897// batch_size,\n",
        "                        epochs=nb_epoch,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=64// batch_size,\n",
        "                        callbacks=callbacks_list)\n",
        "\n",
        "    # save model\n",
        "    model_json = model.to_json()\n",
        "    with open(os.path.join(os.path.abspath(model_path), 'model.json'), 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "    model.save(os.path.join(os.path.abspath(model_path), 'model.h5'))\n",
        "    print('saved!')\n",
        "    files.download(os.path.join(os.path.abspath(model_path), 'model.h5'))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    data_dir = '/content/gdrive/My Drive/erl/data'\n",
        "    train_dir = os.path.join('/content/gdrive/My Drive/erl/data', 'new_train')  # Inside, each class should have it's own folder\n",
        "    validation_dir = os.path.join('/content/gdrive/My Drive/erl/data', 'new_validation')  # each class should have it's own folder\n",
        "    model_dir ='/content/gdrive/My Drive/erl/models'\n",
        "\n",
        "    os.makedirs(os.path.join('/content/gdrive/My Drive/erl/data', 'preview'), exist_ok=True)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    train(train_dir, validation_dir, model_dir)  # train model\n",
        "\n",
        "    # release memory\n",
        "    k.clear_session()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 37, 37, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 19, 19, 728)  2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           65568       global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 20,927,048\n",
            "Trainable params: 20,872,520\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Found 897 images belonging to 32 classes.\n",
            "Found 64 images belonging to 32 classes.\n",
            "Epoch 1/10\n",
            "28/28 [==============================] - 286s 10s/step - loss: 2.6371 - acc: 0.3728 - val_loss: 2.2644 - val_acc: 0.4844\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.48438, saving model to /content/gdrive/My Drive/erl/models/top_model_weights.h5\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 21s 753ms/step - loss: 1.3783 - acc: 0.7699 - val_loss: 1.8044 - val_acc: 0.5781\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.48438 to 0.57812, saving model to /content/gdrive/My Drive/erl/models/top_model_weights.h5\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 25s 908ms/step - loss: 0.9118 - acc: 0.8303 - val_loss: 1.5361 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.57812 to 0.65625, saving model to /content/gdrive/My Drive/erl/models/top_model_weights.h5\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 25s 900ms/step - loss: 0.6658 - acc: 0.8828 - val_loss: 1.3640 - val_acc: 0.6875\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.65625 to 0.68750, saving model to /content/gdrive/My Drive/erl/models/top_model_weights.h5\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 25s 908ms/step - loss: 0.5601 - acc: 0.8906 - val_loss: 1.3159 - val_acc: 0.6406\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.68750\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 25s 904ms/step - loss: 0.4967 - acc: 0.9107 - val_loss: 1.2645 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.68750\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 25s 900ms/step - loss: 0.4624 - acc: 0.9241 - val_loss: 1.1833 - val_acc: 0.7031\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.68750 to 0.70312, saving model to /content/gdrive/My Drive/erl/models/top_model_weights.h5\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 25s 899ms/step - loss: 0.3825 - acc: 0.9174 - val_loss: 1.1705 - val_acc: 0.6406\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.70312\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 25s 886ms/step - loss: 0.3391 - acc: 0.9308 - val_loss: 1.0883 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.70312\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 25s 884ms/step - loss: 0.3122 - acc: 0.9598 - val_loss: 1.0433 - val_acc: 0.6719\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.70312\n",
            "\n",
            "Starting to Fine Tune Model\n",
            "\n",
            "Epoch 1/50\n",
            "28/28 [==============================] - 29s 1s/step - loss: 0.3876 - acc: 0.8940 - val_loss: 0.3219 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.90625, saving model to /content/gdrive/My Drive/erl/models/model_weights.h5\n",
            "Epoch 2/50\n",
            "28/28 [==============================] - 25s 887ms/step - loss: 0.2794 - acc: 0.9364 - val_loss: 3.1182 - val_acc: 0.3750\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.90625\n",
            "Epoch 3/50\n",
            "28/28 [==============================] - 25s 900ms/step - loss: 0.2057 - acc: 0.9532 - val_loss: 0.5091 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.90625\n",
            "Epoch 4/50\n",
            "28/28 [==============================] - 25s 902ms/step - loss: 0.2527 - acc: 0.9577 - val_loss: 1.5226 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.90625\n",
            "Epoch 5/50\n",
            "28/28 [==============================] - 25s 900ms/step - loss: 0.2381 - acc: 0.9543 - val_loss: 1.5062 - val_acc: 0.7656\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.90625\n",
            "Epoch 6/50\n",
            "28/28 [==============================] - 25s 908ms/step - loss: 0.2446 - acc: 0.9577 - val_loss: 0.7682 - val_acc: 0.9375\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.90625 to 0.93750, saving model to /content/gdrive/My Drive/erl/models/model_weights.h5\n",
            "saved!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c966025088f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# release memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-c966025088f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data_dir, validation_data_dir, model_path)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "FFRgaYbhsfZ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download(os.path.join('/content/gdrive/My Drive/erl/models', 'model.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ps3NvUqD7RRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}